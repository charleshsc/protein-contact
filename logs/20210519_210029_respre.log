2021-05-19 21:00:29,937 - 20210519_210029_respre
2021-05-19 21:00:35,634 - Start training...
2021-05-19 21:00:35,642 - Start evaluating...
2021-05-19 21:00:37,956 - Evaluation: 0 / 1219
2021-05-19 21:00:53,413 - Evaluation: 10 / 1219
2021-05-19 21:00:54,728 - Evaluation: 20 / 1219
2021-05-19 21:00:56,357 - Evaluation: 30 / 1219
2021-05-19 21:01:00,524 - Evaluation: 40 / 1219
2021-05-19 21:01:03,720 - Evaluation: 50 / 1219
2021-05-19 21:01:08,729 - Evaluation: 60 / 1219
2021-05-19 21:01:10,794 - Evaluation: 70 / 1219
2021-05-19 21:01:14,354 - Evaluation: 80 / 1219
2021-05-19 21:01:20,779 - Evaluation: 90 / 1219
2021-05-19 21:01:21,731 - Evaluation: 100 / 1219
2021-05-19 21:01:29,766 - Evaluation: 110 / 1219
2021-05-19 21:01:31,311 - Evaluation: 120 / 1219
2021-05-19 21:01:33,037 - Evaluation: 130 / 1219
2021-05-19 21:01:42,236 - Evaluation: 140 / 1219
2021-05-19 21:01:43,678 - Evaluation: 150 / 1219
2021-05-19 21:01:48,556 - Evaluation: 160 / 1219
2021-05-19 21:01:49,675 - Evaluation: 170 / 1219
2021-05-19 21:01:50,783 - Evaluation: 180 / 1219
2021-05-19 21:01:57,892 - Evaluation: 190 / 1219
2021-05-19 21:02:01,472 - Evaluation: 200 / 1219
2021-05-19 21:02:03,539 - Evaluation: 210 / 1219
2021-05-19 21:02:09,677 - Evaluation: 220 / 1219
2021-05-19 21:02:10,754 - Evaluation: 230 / 1219
2021-05-19 21:02:14,027 - Evaluation: 240 / 1219
2021-05-19 21:02:20,161 - Evaluation: 250 / 1219
2021-05-19 21:02:21,643 - Evaluation: 260 / 1219
2021-05-19 21:02:22,979 - Evaluation: 270 / 1219
2021-05-19 21:02:31,865 - Evaluation: 280 / 1219
2021-05-19 21:02:33,085 - Evaluation: 290 / 1219
2021-05-19 21:02:37,250 - Evaluation: 300 / 1219
2021-05-19 21:02:39,340 - Evaluation: 310 / 1219
2021-05-19 21:02:43,524 - Evaluation: 320 / 1219
2021-05-19 21:02:44,796 - Evaluation: 330 / 1219
2021-05-19 21:02:45,635 - Evaluation: 340 / 1219
2021-05-19 21:02:51,022 - Evaluation: 350 / 1219
2021-05-19 21:02:52,806 - Evaluation: 360 / 1219
2021-05-19 21:02:53,888 - Evaluation: 370 / 1219
2021-05-19 21:02:56,948 - Evaluation: 380 / 1219
2021-05-19 21:03:03,042 - Evaluation: 390 / 1219
2021-05-19 21:03:04,500 - Evaluation: 400 / 1219
2021-05-19 21:03:10,177 - Evaluation: 410 / 1219
2021-05-19 21:03:11,175 - Evaluation: 420 / 1219
2021-05-19 21:03:17,116 - Evaluation: 430 / 1219
2021-05-19 21:03:18,428 - Evaluation: 440 / 1219
2021-05-19 21:03:22,279 - Evaluation: 450 / 1219
2021-05-19 21:03:29,311 - Evaluation: 460 / 1219
2021-05-19 21:03:31,009 - Evaluation: 470 / 1219
2021-05-19 21:03:33,734 - Evaluation: 480 / 1219
2021-05-19 21:03:36,156 - Evaluation: 490 / 1219
2021-05-19 21:03:37,370 - Evaluation: 500 / 1219
2021-05-19 21:03:41,163 - Evaluation: 510 / 1219
2021-05-19 21:03:48,231 - Evaluation: 520 / 1219
2021-05-19 21:03:51,085 - Evaluation: 530 / 1219
2021-05-19 21:03:52,796 - Evaluation: 540 / 1219
2021-05-19 21:03:54,522 - Evaluation: 550 / 1219
2021-05-19 21:04:01,093 - Evaluation: 560 / 1219
2021-05-19 21:04:02,816 - Evaluation: 570 / 1219
2021-05-19 21:04:05,715 - Evaluation: 580 / 1219
2021-05-19 21:04:10,021 - Evaluation: 590 / 1219
2021-05-19 21:04:11,502 - Evaluation: 600 / 1219
2021-05-19 21:04:15,303 - Evaluation: 610 / 1219
2021-05-19 21:04:17,181 - Evaluation: 620 / 1219
2021-05-19 21:04:25,931 - Evaluation: 630 / 1219
2021-05-19 21:04:27,757 - Evaluation: 640 / 1219
2021-05-19 21:04:29,159 - Evaluation: 650 / 1219
2021-05-19 21:04:31,032 - Evaluation: 660 / 1219
2021-05-19 21:04:39,739 - Evaluation: 670 / 1219
2021-05-19 21:04:41,331 - Evaluation: 680 / 1219
2021-05-19 21:04:44,743 - Evaluation: 690 / 1219
2021-05-19 21:04:49,335 - Evaluation: 700 / 1219
2021-05-19 21:04:52,945 - Evaluation: 710 / 1219
2021-05-19 21:04:55,756 - Evaluation: 720 / 1219
2021-05-19 21:05:00,553 - Evaluation: 730 / 1219
2021-05-19 21:05:02,038 - Evaluation: 740 / 1219
2021-05-19 21:05:03,210 - Evaluation: 750 / 1219
2021-05-19 21:05:11,435 - Evaluation: 760 / 1219
2021-05-19 21:05:13,466 - Evaluation: 770 / 1219
2021-05-19 21:05:16,001 - Evaluation: 780 / 1219
2021-05-19 21:05:22,779 - Evaluation: 790 / 1219
2021-05-19 21:05:24,012 - Evaluation: 800 / 1219
2021-05-19 21:05:28,912 - Evaluation: 810 / 1219
2021-05-19 21:05:30,539 - Evaluation: 820 / 1219
2021-05-19 21:05:35,091 - Evaluation: 830 / 1219
2021-05-19 21:05:36,755 - Evaluation: 840 / 1219
2021-05-19 21:05:41,791 - Evaluation: 850 / 1219
2021-05-19 21:05:46,891 - Evaluation: 860 / 1219
2021-05-19 21:05:48,541 - Evaluation: 870 / 1219
2021-05-19 21:05:52,502 - Evaluation: 880 / 1219
2021-05-19 21:05:54,225 - Evaluation: 890 / 1219
2021-05-19 21:06:02,211 - Evaluation: 900 / 1219
2021-05-19 21:06:03,831 - Evaluation: 910 / 1219
2021-05-19 21:06:05,291 - Evaluation: 920 / 1219
2021-05-19 21:06:07,428 - Evaluation: 930 / 1219
2021-05-19 21:06:13,123 - Evaluation: 940 / 1219
2021-05-19 21:06:15,473 - Evaluation: 950 / 1219
2021-05-19 21:06:18,317 - Evaluation: 960 / 1219
2021-05-19 21:06:26,345 - Evaluation: 970 / 1219
2021-05-19 21:06:28,014 - Evaluation: 980 / 1219
2021-05-19 21:06:29,773 - Evaluation: 990 / 1219
2021-05-19 21:06:31,228 - Evaluation: 1000 / 1219
2021-05-19 21:06:34,920 - Evaluation: 1010 / 1219
2021-05-19 21:06:36,907 - Evaluation: 1020 / 1219
2021-05-19 21:06:42,562 - Evaluation: 1030 / 1219
2021-05-19 21:06:46,130 - Evaluation: 1040 / 1219
2021-05-19 21:06:48,297 - Evaluation: 1050 / 1219
2021-05-19 21:06:50,385 - Evaluation: 1060 / 1219
2021-05-19 21:06:55,859 - Evaluation: 1070 / 1219
2021-05-19 21:06:58,913 - Evaluation: 1080 / 1219
2021-05-19 21:07:01,175 - Evaluation: 1090 / 1219
2021-05-19 21:07:02,228 - Evaluation: 1100 / 1219
2021-05-19 21:07:07,936 - Evaluation: 1110 / 1219
2021-05-19 21:07:15,088 - Evaluation: 1120 / 1219
2021-05-19 21:07:19,075 - Evaluation: 1130 / 1219
2021-05-19 21:07:20,100 - Evaluation: 1140 / 1219
2021-05-19 21:07:21,357 - Evaluation: 1150 / 1219
2021-05-19 21:07:24,179 - Evaluation: 1160 / 1219
2021-05-19 21:07:29,195 - Evaluation: 1170 / 1219
2021-05-19 21:07:33,338 - Evaluation: 1180 / 1219
2021-05-19 21:07:36,348 - Evaluation: 1190 / 1219
2021-05-19 21:07:38,131 - Evaluation: 1200 / 1219
2021-05-19 21:07:39,034 - Evaluation: 1210 / 1219
2021-05-19 21:07:43,051 - -----------------------EVAL---------------------
Evaluation Result: 1.1613864302635193
2021-05-19 21:07:43,051 - T10: 0.03843991458415985, T5: 0.044909168034791946, T2: 0.07007164508104324, T1: 0.08028026670217514
2021-05-19 21:07:43,051 - LT10: 0.027169641107320786, LT5: 0.023980693891644478, LT2: 0.022965848445892334, LT1: 0.021901164203882217
2021-05-19 21:07:43,052 - Short all result: [0.00019369 0.02067268 0.         0.         0.15556505 0.18427683
 0.0079593  0.00082034 0.02618494 0.        ]

2021-05-19 21:07:45,025 - Epoch: 0, Step: 0, L:149, Loss: 3.4395625591278076
2021-05-19 21:07:52,488 - Epoch: 0, Step: 10, L:288, Loss: 1.5961613655090332
2021-05-19 21:07:55,897 - Epoch: 0, Step: 20, L:310, Loss: 1.1676559388637542
2021-05-19 21:07:59,743 - Epoch: 0, Step: 30, L:218, Loss: 1.3498630404472352
2021-05-19 21:08:02,530 - Epoch: 0, Step: 40, L:109, Loss: 1.3162494838237762
2021-05-19 21:08:04,745 - Epoch: 0, Step: 50, L:203, Loss: 1.1751669883728026
2021-05-19 21:08:07,054 - Epoch: 0, Step: 60, L:179, Loss: 1.3041215896606446
2021-05-19 21:08:09,993 - Epoch: 0, Step: 70, L:186, Loss: 1.2197526216506958
2021-05-19 21:08:14,527 - Epoch: 0, Step: 80, L:178, Loss: 1.174120795726776
2021-05-19 21:08:19,073 - Epoch: 0, Step: 90, L:334, Loss: 1.0913333654403687
2021-05-19 21:08:20,952 - Epoch: 0, Step: 100, L:406, Loss: 1.076318821310997
2021-05-19 21:08:23,758 - Epoch: 0, Step: 110, L:155, Loss: 1.215782105922699
2021-05-19 21:08:30,044 - Epoch: 0, Step: 120, L:143, Loss: 1.1645329415798187
2021-05-19 21:08:33,979 - Epoch: 0, Step: 130, L:152, Loss: 1.0086791425943376
2021-05-19 21:08:35,587 - Epoch: 0, Step: 140, L:193, Loss: 1.3476249694824218
2021-05-19 21:08:39,293 - Epoch: 0, Step: 150, L:162, Loss: 1.172217470407486
2021-05-19 21:08:46,264 - Epoch: 0, Step: 160, L:209, Loss: 1.2032207131385804
2021-05-19 21:08:55,559 - Epoch: 0, Step: 170, L:459, Loss: 0.9732414722442627
2021-05-19 21:08:58,688 - Epoch: 0, Step: 180, L:401, Loss: 1.179760080575943
2021-05-19 21:09:01,171 - Epoch: 0, Step: 190, L:469, Loss: 1.132943195104599
2021-05-19 21:09:04,564 - Epoch: 0, Step: 200, L:213, Loss: 1.1849755644798279
2021-05-19 21:09:07,900 - Epoch: 0, Step: 210, L:380, Loss: 0.9696602940559387
2021-05-19 21:09:09,896 - Epoch: 0, Step: 220, L:130, Loss: 1.1426375210285187
2021-05-19 21:09:13,331 - Epoch: 0, Step: 230, L:330, Loss: 1.2740809202194214
2021-05-19 21:09:18,579 - Epoch: 0, Step: 240, L:208, Loss: 1.377001690864563
2021-05-19 21:09:23,832 - Epoch: 0, Step: 250, L:442, Loss: 1.2197573065757752
2021-05-19 21:09:27,258 - Epoch: 0, Step: 260, L:358, Loss: 1.03374924659729
2021-05-19 21:09:31,214 - Epoch: 0, Step: 270, L:154, Loss: 1.2073848009109498
2021-05-19 21:09:34,451 - Epoch: 0, Step: 280, L:127, Loss: 1.1556541442871093
2021-05-19 21:09:37,273 - Epoch: 0, Step: 290, L:333, Loss: 1.2294866025447846
2021-05-19 21:09:40,732 - Epoch: 0, Step: 300, L:123, Loss: 1.053379774093628
2021-05-19 21:09:54,517 - Epoch: 0, Step: 310, L:189, Loss: 1.0322077691555023
2021-05-19 21:10:03,272 - Epoch: 0, Step: 320, L:164, Loss: 1.1854472041130066
2021-05-19 21:10:07,016 - Epoch: 0, Step: 330, L:450, Loss: 1.018160492181778
2021-05-19 21:10:22,481 - Epoch: 0, Step: 340, L:151, Loss: 1.1354454159736633
2021-05-19 21:10:25,703 - Epoch: 0, Step: 350, L:129, Loss: 1.1542254507541656
2021-05-19 21:10:28,490 - Epoch: 0, Step: 360, L:204, Loss: 1.2005814075469972
2021-05-19 21:10:35,652 - Epoch: 0, Step: 370, L:152, Loss: 1.0157055333256721
2021-05-19 21:10:44,950 - Epoch: 0, Step: 380, L:117, Loss: 1.01291481256485
2021-05-19 21:10:49,088 - Epoch: 0, Step: 390, L:111, Loss: 0.9336918771266938
2021-05-19 21:10:53,447 - Epoch: 0, Step: 400, L:301, Loss: 1.0691606044769286
2021-05-19 21:10:59,611 - Epoch: 0, Step: 410, L:326, Loss: 0.9741912245750427
2021-05-19 21:11:02,590 - Epoch: 0, Step: 420, L:250, Loss: 1.132373070716858
2021-05-19 21:11:11,291 - Epoch: 0, Step: 430, L:375, Loss: 1.13247691988945
2021-05-19 21:11:13,972 - Epoch: 0, Step: 440, L:159, Loss: 1.2605145215988158
2021-05-19 21:11:16,759 - Epoch: 0, Step: 450, L:201, Loss: 1.0290730118751525
2021-05-19 21:11:19,941 - Epoch: 0, Step: 460, L:388, Loss: 1.1303183138370514
2021-05-19 21:11:25,043 - Epoch: 0, Step: 470, L:217, Loss: 0.9555963188409805
2021-05-19 21:11:29,277 - Epoch: 0, Step: 480, L:420, Loss: 1.0153026282787323
2021-05-19 21:11:37,049 - Epoch: 0, Step: 490, L:256, Loss: 0.9934599101543427
2021-05-19 21:11:43,332 - Epoch: 0, Step: 500, L:114, Loss: 1.0876803278923035
2021-05-19 21:11:52,733 - Epoch: 0, Step: 510, L:317, Loss: 1.0555943548679352
2021-05-19 21:11:56,522 - Epoch: 0, Step: 520, L:123, Loss: 1.151621663570404
2021-05-19 21:12:00,342 - Epoch: 0, Step: 530, L:335, Loss: 1.0356347918510438
2021-05-19 21:12:08,738 - Epoch: 0, Step: 540, L:159, Loss: 1.1218083381652832
2021-05-19 21:12:21,600 - Epoch: 0, Step: 550, L:241, Loss: 1.0055897533893585
2021-05-19 21:12:26,202 - Epoch: 0, Step: 560, L:116, Loss: 0.9923361420631409
2021-05-19 21:12:29,205 - Epoch: 0, Step: 570, L:234, Loss: 1.0162348926067353
2021-05-19 21:12:32,966 - Epoch: 0, Step: 580, L:122, Loss: 1.0630111515522003
2021-05-19 21:12:42,289 - Epoch: 0, Step: 590, L:340, Loss: 1.042862093448639
2021-05-19 21:12:49,389 - Epoch: 0, Step: 600, L:275, Loss: 0.982053816318512
2021-05-19 21:12:53,169 - Epoch: 0, Step: 610, L:391, Loss: 1.154823476076126
2021-05-19 21:13:01,777 - Epoch: 0, Step: 620, L:284, Loss: 0.9512671947479248
2021-05-19 21:13:04,635 - Epoch: 0, Step: 630, L:304, Loss: 1.1152547657489777
2021-05-19 21:13:07,815 - Epoch: 0, Step: 640, L:130, Loss: 0.9843776226043701
2021-05-19 21:13:14,928 - Epoch: 0, Step: 650, L:162, Loss: 0.9727956175804138
2021-05-19 21:13:19,812 - Epoch: 0, Step: 660, L:406, Loss: 0.9067323446273804
2021-05-19 21:13:26,258 - Epoch: 0, Step: 670, L:197, Loss: 0.8600311517715454
2021-05-19 21:13:33,342 - Epoch: 0, Step: 680, L:318, Loss: 1.0625551760196685
2021-05-19 21:13:37,840 - Epoch: 0, Step: 690, L:287, Loss: 0.9517464876174927
2021-05-19 21:13:42,488 - Epoch: 0, Step: 700, L:296, Loss: 1.1138901948928832
2021-05-19 21:13:47,292 - Epoch: 0, Step: 710, L:225, Loss: 1.125187051296234
2021-05-19 21:13:54,484 - Epoch: 0, Step: 720, L:105, Loss: 1.0082718104124069
2021-05-19 21:13:58,087 - Epoch: 0, Step: 730, L:305, Loss: 1.06297647356987
2021-05-19 21:14:00,555 - Epoch: 0, Step: 740, L:162, Loss: 1.1444135010242462
2021-05-19 21:14:02,447 - Epoch: 0, Step: 750, L:168, Loss: 1.0733008325099944
2021-05-19 21:14:05,188 - Epoch: 0, Step: 760, L:131, Loss: 1.1025799870491029
2021-05-19 21:14:10,903 - Epoch: 0, Step: 770, L:108, Loss: 1.0716476678848266
2021-05-19 21:14:14,844 - Epoch: 0, Step: 780, L:378, Loss: 0.9043880641460419
2021-05-19 21:14:17,718 - Epoch: 0, Step: 790, L:293, Loss: 0.9733266353607177
2021-05-19 21:14:21,471 - Epoch: 0, Step: 800, L:440, Loss: 0.9331628084182739
2021-05-19 21:14:24,544 - Epoch: 0, Step: 810, L:364, Loss: 0.9600943088531494
2021-05-19 21:14:27,295 - Epoch: 0, Step: 820, L:272, Loss: 1.0387814700603486
2021-05-19 21:14:34,797 - Epoch: 0, Step: 830, L:188, Loss: 0.924057000875473
2021-05-19 21:14:39,193 - Epoch: 0, Step: 840, L:270, Loss: 0.8541847407817841
2021-05-19 21:14:46,040 - Epoch: 0, Step: 850, L:383, Loss: 1.0964861810207367
2021-05-19 21:14:55,072 - Epoch: 0, Step: 860, L:271, Loss: 0.9495614171028137
2021-05-19 21:15:01,196 - L=471
2021-05-19 21:15:01,197 - CUDA out of memory. Tried to allocate 56.00 MiB (GPU 0; 10.76 GiB total capacity; 6.21 GiB already allocated; 46.56 MiB free; 6.42 GiB reserved in total by PyTorch)
2021-05-19 21:15:04,740 - Epoch: 0, Step: 870, L:145, Loss: 0.9810548159811232
2021-05-19 21:15:15,796 - Epoch: 0, Step: 880, L:365, Loss: 0.9164792656898498
2021-05-19 21:15:19,318 - Epoch: 0, Step: 890, L:302, Loss: 1.0020362973213195
2021-05-19 21:15:22,225 - Epoch: 0, Step: 900, L:138, Loss: 1.1408477544784545
2021-05-19 21:15:26,016 - Epoch: 0, Step: 910, L:242, Loss: 1.1029567897319794
2021-05-19 21:15:32,878 - Epoch: 0, Step: 920, L:133, Loss: 1.0814418613910675
2021-05-19 21:15:35,477 - Epoch: 0, Step: 930, L:125, Loss: 1.1465324580669403
2021-05-19 21:15:39,521 - Epoch: 0, Step: 940, L:164, Loss: 1.0028296828269958
2021-05-19 21:15:49,766 - Epoch: 0, Step: 950, L:164, Loss: 1.173919492959976
2021-05-19 21:15:51,895 - Epoch: 0, Step: 960, L:139, Loss: 1.133419394493103
2021-05-19 21:16:01,443 - Epoch: 0, Step: 970, L:474, Loss: 0.9690978944301605
2021-05-19 21:16:04,829 - Epoch: 0, Step: 980, L:191, Loss: 0.9646518409252167
2021-05-19 21:16:06,789 - L=314
2021-05-19 21:16:06,792 - CUDA out of memory. Tried to allocate 26.00 MiB (GPU 0; 10.76 GiB total capacity; 2.71 GiB already allocated; 8.56 MiB free; 2.92 GiB reserved in total by PyTorch)
2021-05-19 21:16:11,679 - Epoch: 0, Step: 990, L:332, Loss: 0.8578211466471354
2021-05-19 21:16:14,749 - Epoch: 0, Step: 1000, L:134, Loss: 0.970078068971634
2021-05-19 21:16:23,679 - Epoch: 0, Step: 1010, L:224, Loss: 0.8917865216732025
2021-05-19 21:16:26,980 - Epoch: 0, Step: 1020, L:329, Loss: 1.046608966588974
2021-05-19 21:16:36,128 - Epoch: 0, Step: 1030, L:205, Loss: 0.9934846639633179
2021-05-19 21:16:39,989 - L=378
2021-05-19 21:16:39,989 - CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 10.76 GiB total capacity; 3.23 GiB already allocated; 22.56 MiB free; 3.35 GiB reserved in total by PyTorch)
2021-05-19 21:16:41,213 - Epoch: 0, Step: 1040, L:112, Loss: 1.0071025358306036
2021-05-19 21:16:53,942 - L=288
2021-05-19 21:16:53,943 - CUDA out of memory. Tried to allocate 22.00 MiB (GPU 0; 10.76 GiB total capacity; 1.57 GiB already allocated; 22.56 MiB free; 1.69 GiB reserved in total by PyTorch)
2021-05-19 21:16:54,363 - Epoch: 0, Step: 1050, L:125, Loss: 1.0375712381468878
2021-05-19 21:17:01,585 - Epoch: 0, Step: 1060, L:119, Loss: 1.0811490714550018
2021-05-19 21:17:06,014 - Epoch: 0, Step: 1070, L:226, Loss: 1.030396443605423
2021-05-19 21:17:10,138 - Epoch: 0, Step: 1080, L:438, Loss: 0.990933644771576
2021-05-19 21:17:14,158 - Epoch: 0, Step: 1090, L:139, Loss: 1.1712896049022674
2021-05-19 21:17:17,401 - Epoch: 0, Step: 1100, L:195, Loss: 1.028436440229416
2021-05-19 21:17:23,057 - Epoch: 0, Step: 1110, L:214, Loss: 0.9800749301910401
2021-05-19 21:17:34,967 - Epoch: 0, Step: 1120, L:187, Loss: 1.019560420513153
2021-05-19 21:17:36,473 - L=425
2021-05-19 21:17:36,473 - CUDA out of memory. Tried to allocate 46.00 MiB (GPU 0; 10.76 GiB total capacity; 4.89 GiB already allocated; 4.56 MiB free; 5.09 GiB reserved in total by PyTorch)
2021-05-19 21:17:37,019 - L=384
2021-05-19 21:17:37,019 - CUDA out of memory. Tried to allocate 36.00 MiB (GPU 0; 10.76 GiB total capacity; 4.03 GiB already allocated; 38.56 MiB free; 5.09 GiB reserved in total by PyTorch)
2021-05-19 21:17:41,106 - Epoch: 0, Step: 1130, L:123, Loss: 0.9740378335118294
2021-05-19 21:17:48,011 - Epoch: 0, Step: 1140, L:140, Loss: 0.9269020438194275
2021-05-19 21:17:50,990 - Epoch: 0, Step: 1150, L:134, Loss: 1.1440916180610656
2021-05-19 21:17:58,971 - Epoch: 0, Step: 1160, L:339, Loss: 0.901095274090767
2021-05-19 21:18:02,269 - Epoch: 0, Step: 1170, L:205, Loss: 1.015343999862671
